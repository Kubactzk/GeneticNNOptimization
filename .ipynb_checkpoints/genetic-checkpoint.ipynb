{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a78f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tools import MetricsHistory\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a9b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "X_data_dir = r\"D:\\Studia\\ISA-magister\\sem_1\\Algorytmy_optymalizacji\\Projekt\\Repo\\nn-arc-optimization\\output_files\\X_scaled.csv\"\n",
    "y_data_dir = r\"D:\\Studia\\ISA-magister\\sem_1\\Algorytmy_optymalizacji\\Projekt\\Repo\\nn-arc-optimization\\output_files\\y.csv\"\n",
    "\n",
    "X_data = pd.read_csv(X_data_dir)\n",
    "y_data = pd.read_csv(y_data_dir)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4ced3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define populatio size (num. of networks)\n",
    "pupulation_size = 4\n",
    "\n",
    "#define generations\n",
    "generations = 5\n",
    "\n",
    "#define miation propabiliry\n",
    "mutation_prob = 0.3\n",
    "\n",
    "#define crossover propability \n",
    "cross_prob = 0.5\n",
    "\n",
    "#define input shape for neural network\n",
    "Input = 30\n",
    "\n",
    "all_val_losses = []\n",
    "all_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903f1c5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Individual():\n",
    "    n_layers = random.randint(1,3)\n",
    "    r_optimizer = random.choice([keras.optimizers.RMSprop(),'adam','sgd'])\n",
    "    neurons=[]\n",
    "    for i in range(n_layers):\n",
    "        neurons.append(random.randint(1,32))\n",
    "    #neurons.sort(reverse=True)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=Input, activation='relu'))\n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(neurons[i], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=r_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_population(pupulation_size):\n",
    "    models = []\n",
    "    for _ in range(pupulation_size):\n",
    "        models.append(Individual())\n",
    "    models = list(set(models))\n",
    "    return models\n",
    "\n",
    "def evaluate(individual):\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5, restore_best_weights=True)\n",
    "    metrics_history = MetricsHistory()\n",
    "    history = individual.fit(x_train, y_train, validation_split=0.2, epochs=50, batch_size=1, verbose=0, callbacks=[es,metrics_history])\n",
    "    #pupulation[i].save(f'genetic_output_files/genetic_model_initial_individuals{i}.h5')\n",
    "    all_accuracies.append(metrics_history.accuracy)\n",
    "    all_val_losses.append(metrics_history.val_loss)\n",
    "    _, test_accuracy = individual.evaluate(x_test, y_test, verbose=0) \n",
    "    return test_accuracy\n",
    "\n",
    "def selection(population, fitnesses, num_parents):\n",
    "    sorted_indices = np.argsort(fitnesses)[::-1]\n",
    "    return [population[i] for i in sorted_indices[:num_parents]]\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    \"\"\"Krzyżowanie dwóch rodziców w celu utworzenia dwóch dzieci.\"\"\"\n",
    "    parent1_layers = parent1.layers\n",
    "    parent2_layers = parent2.layers\n",
    "\n",
    "    point1 = random.randint(1, min(len(parent1_layers), len(parent2_layers)) - 1)\n",
    "    point2 = random.randint(point1, min(len(parent1_layers), len(parent2_layers)) - 1)\n",
    "\n",
    "    child1_layers = [layer.get_config() for layer in parent1_layers]\n",
    "    child2_layers = [layer.get_config() for layer in parent2_layers]\n",
    "\n",
    "    for i in range(point1, point2):\n",
    "        child1_layers[i] = parent2_layers[i].get_config()\n",
    "        child2_layers[i] = parent1_layers[i].get_config()\n",
    "\n",
    "      # Creating new models\n",
    "    child1_model = Sequential()\n",
    "    child2_model = Sequential()\n",
    "\n",
    "    for layer_config in child1_layers:\n",
    "        layer = Dense.from_config(layer_config)\n",
    "        child1_model.add(layer)\n",
    "\n",
    "    for layer_config in child2_layers:\n",
    "        layer = Dense.from_config(layer_config)\n",
    "        child2_model.add(layer)\n",
    "        \n",
    "    # Creating new optimizers for child models\n",
    "    child1_optimizer = parent1.optimizer.__class__.from_config(parent1.optimizer.get_config())\n",
    "    child2_optimizer = parent2.optimizer.__class__.from_config(parent2.optimizer.get_config())\n",
    "    # Compiling new models\n",
    "    child1_model.compile(optimizer=child1_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    child2_model.compile(optimizer=child2_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return child1_model, child2_model\n",
    "\n",
    "# def mutate(individual):\n",
    "#     if random.random() < mutation_prob:\n",
    "#         mutation_type = random.choice(['n_layers', 'neurons', 'optimizer'])\n",
    "#         if mutation_type == 'n_layers':\n",
    "#             individual['n_layers'] = random.randint(1, 4)\n",
    "#         elif mutation_type == 'neurons':\n",
    "#             individual['neurons'] = [random.randint(1, 100) for _ in range(individual['n_layers'])]\n",
    "#             individual['neurons'].sort(reverse=True)\n",
    "#         elif mutation_type == 'optimizer':\n",
    "#             individual['optimizer'] = random.choice(['rmsprop', 'adam', 'sgd'])\n",
    "#     return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa54596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    population = create_population(pupulation_size)\n",
    "    \n",
    "    for generation in range(generations):\n",
    "        #print(F\"ITERACJA {generation+1}\")\n",
    "        fitnesses = [evaluate(model) for model in population]\n",
    "        parents = selection(population, fitnesses, pupulation_size // 2)\n",
    "        next_generation = []\n",
    "\n",
    "        for i in range(0, len(parents), 2):\n",
    "            parent1, parent2 = parents[i], parents[(i + 1) % len(parents)]\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            next_generation.append(child1)\n",
    "            next_generation.append(child2)\n",
    "        population = next_generation\n",
    "        best_fitness = max(fitnesses)\n",
    "        print(f'Generation {generation}, Best Fitness: {best_fitness}')\n",
    "        \n",
    "    best_individual = population[np.argmax(fitnesses)]\n",
    "    print('Best Individual:', best_individual)\n",
    "    print(\"all\", len(fitnesses))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sub_array in enumerate(all_val_losses, start=1):\n",
    "    plt.plot(sub_array, label=f'Array {i}')\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Plots of Arrays')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045fe2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sub_array in enumerate(all_accuracies, start=1):\n",
    "    plt.plot(sub_array, label=f'Array {i}')\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Plots of Arrays')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create an individual\n",
    "\n",
    "# def Individual():\n",
    "#     n_layers = random.randint(1,4)\n",
    "#     r_optimizer = random.choice([keras.optimizers.RMSprop(),'adam','sgd'])\n",
    "#     neurons=[]\n",
    "#     for i in range(n_layers):\n",
    "#         neurons.append(random.randint(1,100))\n",
    "#     neurons.sort(reverse=True)\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(30, input_dim=Input, activation='relu'))\n",
    "#     for i in range(n_layers):\n",
    "#         model.add(Dense(neurons[i], activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(optimizer=r_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# def create_population():\n",
    "#     return [Individual() for _ in range(pupulation_size)]\n",
    "\n",
    "# def evaluate(pupulation):\n",
    "#     all_accuracies = []\n",
    "#     all_val_losses = []\n",
    "#     all_test_accuracies = []\n",
    "#     es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
    "#     for i in range(len(pupulation)):\n",
    "#         metrics_history = MetricsHistory()\n",
    "#         history = pupulation[i].fit(x_train, y_train, validation_split=0.2, epochs=50, batch_size=1, verbose=1, callbacks=[es,metrics_history])\n",
    "#         pupulation[i].save(f'genetic_output_files/genetic_model_initial_individuals{i}.h5')\n",
    "#         all_accuracies.append(metrics_history.accuracy)\n",
    "#         all_val_losses.append(metrics_history.val_loss)\n",
    "#         _, test_accuracy = pupulation[i].evaluate(x_test, y_test, verbose=0) \n",
    "#         all_test_accuracies.append(test_accuracy)\n",
    "#     return all_test_accuracies,all_accuracies,all_val_losses\n",
    "\n",
    "# def selection(population, fitnesses, num_parents):\n",
    "#     \"\"\"Selekcja najlepszych osobników do krzyżowania.\"\"\"\n",
    "#     sorted_indices = np.argsort(fitnesses)[::-1]\n",
    "#     x = [population[i] for i in sorted_indices[:num_parents]]\n",
    "#     parent_paths = []\n",
    "#     for i in range(len(x)):\n",
    "#         parent_paths.append(\"D:\\\\Studia\\\\ISA-magister\\\\sem_1\\\\Algorytmy_optymalizacji\\\\Projekt\\\\Repo\\\\nn-arc-optimization\\\\genetic\\\\genetic_output_files\\\\\"+x[i])\n",
    "        \n",
    "#     return parent_paths\n",
    "\n",
    "# # #calculate parents\n",
    "# # num_parents = pupulation_size // 2\n",
    "\n",
    "\n",
    "# #create a list with every acc and name od model\n",
    "\n",
    "# # crossover\n",
    "# def crossover(parent1_path, parent2_path):\n",
    "#     # Wczytanie modeli rodziców\n",
    "#     parent1 = keras.models.load_model(parent1_path)\n",
    "#     parent2 = keras.models.load_model(parent2_path)\n",
    "    \n",
    "#     # Pobranie hiperparametrów z modeli rodziców\n",
    "#     parent1_layers = parent1.layers\n",
    "#     parent2_layers = parent2.layers\n",
    "    \n",
    "#     point1 = random.randint(1, min(len(parent1_layers), len(parent2_layers)) - 1)\n",
    "#     point2 = random.randint(point1, min(len(parent1_layers), len(parent2_layers)) - 1)\n",
    "    \n",
    "#     child1_layers = [layer.get_config() for layer in parent1_layers]\n",
    "#     child2_layers = [layer.get_config() for layer in parent2_layers]\n",
    "    \n",
    "#     for i in range(point1, point2):\n",
    "#         child1_layers[i] = parent2_layers[i].get_config()\n",
    "#         child2_layers[i] = parent1_layers[i].get_config()\n",
    "        \n",
    "#       # Creating new models\n",
    "#     child1_model = Sequential()\n",
    "#     child2_model = Sequential()\n",
    "    \n",
    "#     for layer_config in child1_layers:\n",
    "#         layer = Dense.from_config(layer_config)\n",
    "#         child1_model.add(layer)\n",
    "    \n",
    "#     for layer_config in child2_layers:\n",
    "#         layer = Dense.from_config(layer_config)\n",
    "#         child2_model.add(layer)\n",
    "    \n",
    "#     # Compiling new models\n",
    "#     child1_model.compile(optimizer=parent1.optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     child2_model.compile(optimizer=parent2.optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     children = [child1_model, child2_model]\n",
    "#     return child1_model, child2_model\n",
    "\n",
    "# # Mutacja pojedynczego osobnika\n",
    "# def mutate(individual, mutation_prob):\n",
    "#     mutated_individual = []\n",
    "#     for layer in individual.layers:\n",
    "#         mutated_layer = layer\n",
    "#         if random.random() < mutation_prob:\n",
    "#             mutated_layer.set_weights([mutated_layer.get_weights()[0] + np.random.normal(0, 0.1, mutated_layer.get_weights()[0].shape),\n",
    "#                                        mutated_layer.get_weights()[1] + np.random.normal(0, 0.1, mutated_layer.get_weights()[1].shape)])\n",
    "#         mutated_individual.append(mutated_layer)\n",
    "#     return mutated_individual\n",
    "\n",
    "\n",
    "# # Tworzenie kolejnej generacji\n",
    "# def create_next_generation(parents, population_size, mutation_prob):\n",
    "#     next_generation = []\n",
    "#     num_parents = len(parents)\n",
    "#     while len(next_generation) < population_size:\n",
    "#         parent1, parent2 = random.sample(parents, 2)\n",
    "#         child1, child2 = crossover(parent1, parent2)\n",
    "#         next_generation.append(mutate(child1, mutation_prob))\n",
    "#         if len(next_generation) < population_size:\n",
    "#             next_generation.append(mutate(child2, mutation_prob))\n",
    "#     return next_generation\n",
    "\n",
    "\n",
    "# #main code\n",
    "# population = create_population()\n",
    "# all_test_accuracies,all_accuracies,all_val_losses = evaluate(population)\n",
    "\n",
    "# models_dir =  r\"D:\\Studia\\ISA-magister\\sem_1\\Algorytmy_optymalizacji\\Projekt\\Repo\\nn-arc-optimization\\genetic\\genetic_output_files\"\n",
    "# fitnesses = []\n",
    "# files = os.listdir(models_dir)\n",
    "# for i in range (len(files)):\n",
    "#     fitnesses.append([test_accuracy[i],files[i]])\n",
    "#     files.sort()\n",
    "#     files = sorted(files, key=lambda x: int(x.split('.')[0].split('individuals')[-1]))\n",
    "# num_parents = len(files)//2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
